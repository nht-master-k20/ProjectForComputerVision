import sys
import os
import random
import numpy as np
import pandas as pd
import torch
import timm
import mlflow
import mlflow.pytorch
from torch.utils.data import DataLoader
from sklearn.metrics import f1_score, accuracy_score, classification_report, roc_auc_score, recall_score

# --- 1. FIX PATH IMPORT ---
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

# Import Dataset (Kiá»ƒm tra ká»¹ tÃªn file ISICDataset hay ISICDataset2 trong folder scripts)
from scripts.ISICDataset2 import ISICDataset


# --- 0. SEED CONTROL ---
def seed_everything(seed=42):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


# --- 1. HELPERS ---
def calculate_metrics(y_true, y_probs, threshold=0.5):
    y_pred = (y_probs >= threshold).astype(int)
    try:
        pauc = roc_auc_score(y_true, y_probs, max_fpr=0.01)
        auc = roc_auc_score(y_true, y_probs)
    except:
        pauc, auc = 0.0, 0.0

    return {
        "pauc_0.01": pauc,
        "auc": auc,
        "f1_malignant": f1_score(y_true, y_pred, labels=[1], average='binary', zero_division=0),
        "recall_malignant": recall_score(y_true, y_pred, labels=[1], average='binary', zero_division=0),
        "accuracy": accuracy_score(y_true, y_pred)
    }


def log_inference_params(tta_steps):
    params = {
        "version": "v4_Inference_TTA",
        "base_model": "V3_Advanced (Loaded Checkpoint)",
        "inference_strategy": f"Test Time Augmentation (Steps={tta_steps})",
        "metric_target": "pAUC (0.01)"
    }
    mlflow.log_params(params)


# --- 2. TTA CORE FUNCTION ---
def predict_tta(model, loader, tta_steps=5, device='cuda'):
    """
    Cháº¡y dá»± Ä‘oÃ¡n nhiá»u láº§n trÃªn cÃ¹ng 1 táº­p dá»¯ liá»‡u (vá»›i Augmentation khÃ¡c nhau)
    vÃ  láº¥y trung bÃ¬nh cá»™ng.
    """
    model.eval()

    # Sá»‘ lÆ°á»£ng máº«u trong táº­p test
    num_samples = len(loader.dataset)

    # Máº£ng cá»™ng dá»“n xÃ¡c suáº¥t (Khá»Ÿi táº¡o báº±ng 0)
    accumulated_probs = np.zeros(num_samples)
    final_labels = None

    print(f"ðŸ”„ Starting TTA ({tta_steps} views per image)...")

    with torch.no_grad():
        for i in range(tta_steps):
            print(f"   â–º View {i + 1}/{tta_steps}")
            step_probs = []
            step_labels = []

            for imgs, labels in loader:
                imgs = imgs.to(device)

                # Forward
                outputs = model(imgs)  # Logits

                # Sigmoid Ä‘á»ƒ ra xÃ¡c suáº¥t (0-1)
                probs = torch.sigmoid(outputs).cpu().numpy().flatten()

                step_probs.extend(probs)
                step_labels.extend(labels.cpu().numpy())

            # Cá»™ng dá»“n xÃ¡c suáº¥t cá»§a láº§n cháº¡y nÃ y vÃ o tá»•ng
            accumulated_probs += np.array(step_probs)

            # LÆ°u labels (Chá»‰ cáº§n lÆ°u 1 láº§n vÃ¬ thá»© tá»± khÃ´ng Ä‘á»•i)
            if final_labels is None:
                final_labels = np.array(step_labels)

    # Chia trung bÃ¬nh
    avg_probs = accumulated_probs / tta_steps
    return final_labels, avg_probs


# --- 3. MAIN FUNCTION ---
# LÆ°u Ã½: HÃ m nÃ y tÃªn lÃ  run_tta Ä‘á»ƒ main.py gá»i Ä‘Ãºng
def run_tta(image_size=300, batch_size=32, tta_steps=5):
    # Setup
    seed_everything(42)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ðŸ–¥ï¸ Running V4 (Inference TTA) on {device}...")

    # MLflow
    os.environ["DATABRICKS_HOST"] = "https://dbc-cba55001-5dea.cloud.databricks.com"
    os.environ["DATABRICKS_TOKEN"] = "dapif865faf65e4f29f9f213de9b6f2ffa3c"
    mlflow.set_tracking_uri("databricks")
    mlflow.set_experiment("/Workspace/Users/nht.master.k20@gmail.com/v4")

    # Load Data (Chá»‰ cáº§n táº­p Test)
    CSV_DIR = os.path.join(parent_dir, 'dataset_splits')
    test_path = f'{CSV_DIR}/processed_test.csv'

    if not os.path.exists(test_path):
        print(f"âŒ Error: KhÃ´ng tÃ¬m tháº¥y {test_path}")
        return

    test_df = pd.read_csv(test_path)
    print(f"ðŸ“Š Test Data: {len(test_df)} samples")

    # --- DATALOADER CHO TTA ---
    # QUAN TRá»ŒNG 1: is_train=True -> Äá»ƒ Báº¬T Augmentation (Xoay, Láº­t...)
    # QUAN TRá»ŒNG 2: shuffle=False -> Äá»ƒ thá»© tá»± áº£nh giá»¯ nguyÃªn qua cÃ¡c vÃ²ng láº·p, cá»™ng dá»“n Ä‘Ãºng index
    tta_loader = DataLoader(
        ISICDataset(test_df, image_size, is_train=True),
        batch_size=batch_size,
        shuffle=False,
        num_workers=8, pin_memory=True
    )

    # --- LOAD MODEL V3 ---
    # ÄÆ°á»ng dáº«n file checkpoint V3
    ckpt_dir = os.path.join(parent_dir, 'checkpoints')
    model_path = os.path.join(ckpt_dir, "best_v3.pth")

    if not os.path.exists(model_path):
        print(f"âŒ Error: KhÃ´ng tÃ¬m tháº¥y model V3 táº¡i {model_path}!")
        print("ðŸ‘‰ HÃ£y cháº¡y 'python main.py v3' Ä‘á»ƒ train xong V3 trÆ°á»›c.")
        return

    print("ðŸ—ï¸ Loading Model V3 structure (EfficientNet-B3 Binary)...")
    model = timm.create_model("tf_efficientnet_b3.ns_jft_in1k", pretrained=False, num_classes=1)

    print(f"ðŸ“‚ Loading Weights from {model_path}...")
    checkpoint = torch.load(model_path)
    model.load_state_dict(checkpoint)
    model.to(device)

    # --- RUN INFERENCE ---
    with mlflow.start_run(run_name="V4_TTA_Inference"):
        log_inference_params(tta_steps)

        # Cháº¡y TTA
        labels, avg_probs = predict_tta(model, tta_loader, tta_steps=tta_steps, device=device)

        # TÃ­nh metrics
        metrics = calculate_metrics(labels, avg_probs)

        print("\n" + "=" * 40)
        print(f"ðŸ† FINAL RESULT (V4 - TTA {tta_steps}x)")
        print(f"pAUC (0.01): {metrics['pauc_0.01']:.4f}")
        print(f"AUC Full   : {metrics['auc']:.4f}")
        print(f"F1 Mal     : {metrics['f1_malignant']:.4f}")
        print(f"Recall Mal : {metrics['recall_malignant']:.4f}")
        print("=" * 40)

        print(classification_report(labels, (avg_probs >= 0.5).astype(int), target_names=['Benign', 'Malignant']))

        # Log metrics
        mlflow.log_metrics({f"test_{k}": v for k, v in metrics.items()})

        # LÆ°u káº¿t quáº£ dá»± Ä‘oÃ¡n ra file CSV Ä‘á»ƒ ná»™p bÃ i hoáº·c phÃ¢n tÃ­ch
        output_file = "v4_tta_predictions.csv"
        result_df = pd.DataFrame({'label': labels, 'prob_tta': avg_probs})
        result_df.to_csv(output_file, index=False)
        print(f"ðŸ’¾ Saved predictions to {output_file}")