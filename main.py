import argparse
import random
import sys
import os
import torch
import numpy as np

# --- 1. SETUP PATHS (QUAN TR·ªåNG NH·∫§T) ---
# Th√™m th∆∞ m·ª•c hi·ªán t·∫°i v√†o sys.path ƒë·ªÉ Python t√¨m th·∫•y 'scripts' v√† 'models'
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)

# --- 2. C·∫§U H√åNH CHUNG ---
CONFIG = {
    "image_size": 300,
    "batch_size": 32,
    "epochs": 10,
    "lr": 1e-3,
    "tta_steps": 5,  # D√†nh ri√™ng cho V4
    "seed": 42
}


def seed_everything(seed):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


# --- 3. X·ª¨ L√ù CH√çNH ---
def run_task(task_name):
    print(f"\n[MAIN] üöÄ K√≠ch ho·∫°t t√°c v·ª•: {task_name.upper()}")
    seed_everything(CONFIG['seed'])

    # --- T√ÅC V·ª§ 1: CHU·∫®N B·ªä D·ªÆ LI·ªÜU ---
    if task_name == 'data':
        try:
            # Import t·ª´ scripts/prepare_data.py
            from scripts.prepare_data import ReadData
            print(f"   ‚öôÔ∏è [DATA] B·∫Øt ƒë·∫ßu quy tr√¨nh: Clean -> Resize -> Split")
            ReadData.run()
        except ImportError:
            print("‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file 'scripts/prepare_data.py'")
        except Exception as e:
            print(f"‚ùå L·ªói x·ª≠ l√Ω d·ªØ li·ªáu: {e}")
        return

    # --- T√ÅC V·ª§ 2: TRAINING (V1, V2, V3) ---
    if task_name in ['v1', 'v2', 'v3']:
        try:
            # Dynamic Import: models.v1, models.v2, ...
            # Gi·∫£ ƒë·ªãnh b·∫°n l∆∞u file code train v√†o folder 'models/' v·ªõi t√™n v1.py, v2.py...
            module = __import__(f"models.{task_name}", fromlist=['train'])

            print(f"   ‚öôÔ∏è [TRAIN] C·∫•u h√¨nh: {CONFIG}")
            module.train(
                image_size=CONFIG['image_size'],
                batch_size=CONFIG['batch_size'],
                epochs=CONFIG['epochs'],
                base_lr=CONFIG['lr']
            )
        except ImportError as e:
            print(f"‚ùå L·ªói Import: Kh√¥ng t√¨m th·∫•y file 'models/{task_name}.py'.\n   Chi ti·∫øt: {e}")
        except AttributeError:
            print(f"‚ùå L·ªói Code: File 'models/{task_name}.py' kh√¥ng c√≥ h√†m 'train()'.")
        except Exception as e:
            print(f"‚ùå L·ªói trong qu√° tr√¨nh Train {task_name}: {e}")
            raise e
        return

    # --- T√ÅC V·ª§ 3: INFERENCE TTA (V4) ---
    if task_name == 'v4':
        try:
            # V4 l√† Inference, g·ªçi h√†m run_tta
            from models import v4

            print(f"   ‚öôÔ∏è [INFERENCE] C·∫•u h√¨nh TTA: {CONFIG['tta_steps']} steps")
            v4.run_tta(
                image_size=CONFIG['image_size'],
                batch_size=CONFIG['batch_size'],
                tta_steps=CONFIG['tta_steps']
            )
        except ImportError as e:
            print(f"‚ùå L·ªói Import: Kh√¥ng t√¨m th·∫•y file 'models/v4.py'.\n   Chi ti·∫øt: {e}")
        except Exception as e:
            print(f"‚ùå L·ªói trong qu√° tr√¨nh Inference V4: {e}")
            raise e
        return

    print(f"‚ùå T√°c v·ª• '{task_name}' kh√¥ng h·ª£p l·ªá.")


# --- 4. ENTRY POINT ---
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Skin Cancer Classification Pipeline')

    parser.add_argument('task', type=str,
                        choices=['data', 'v1', 'v2', 'v3', 'v4'],
                        help='Ch·ªçn t√°c v·ª• ƒë·ªÉ ch·∫°y: data (x·ª≠ l√Ω), v1-v3 (train), v4 (inference TTA)')

    args = parser.parse_args()

    run_task(args.task)